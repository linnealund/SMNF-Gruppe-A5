---
title: "Living Document"
date: today
author: "Melina Esen, Eric Ansorge, Sophie Spektor, Lina Woeste und Linnea Lund"
format:
    html: default
    pdf:
      papersize: "a4"
      fontsize: "12"
      number-sections: true
      number-depth: 1
      
editor: visual
bibliography: references.bib
csl: apa.csl
style: "american-psychological-association"
lang: de
---

**GitHub Repository:** https://github.com/linnealund/SMNF-Gruppe-A5

**Für die Abgabe aktueller GitHub Hash:** SOME_HASH

## **Code of Conduct**

Im Rahmen unserer Zusammenarbeit als Projektgruppe halten wir einen Verhaltenskodex ein, der wie folgt definiert ist:

**Umgang mit Feedback und Meinungsverschiedenheiten**

Wir begegnen Meinungsverschiedenheiten stets offen und ermutigen kritisches Denken. Jeder soll die Möglichkeit haben Bedenken, Gedanken und Meinungen frei äußern zu dürfen, ohne dafür diskriminiert zu werden. Dabei legen wir Wert auf konstruktives Feedback.

**Faire Aufteilung der Arbeitslast**

Die Einzelnen Aufgaben werden gleichmäßig verteilt, so dass jeder ähnlich viel machen muss. Dabei achten wir auf Stärken und Schwächen jedes einzelnen und gehen bei der Verteilung auf diese ein.

**Verhalten in Bezug auf vereinbarte und verpflichtende Termine**

Jeder hat die Verantwortung vereinbarte Termine wahrzunehmen. Sollte es aus Gründen dazu kommen, dass besagter Termin nicht wahrgenommen werden kann, so muss rechtzeitig Bescheid gegeben werden. So kann den anderen Mitgliedern eine Umplanung ermöglicht werden.

**Wissenschaftliche Integrität**

Wir halten uns an die Grundsätze guten wissenschaftlichen Arbeitens. Dazu gehören Ehrlichkeit, Genauigkeit, Objektivität sowie der verantwortungsvolle Umgang mit Daten und Quellen. Plagiate, Datenmanipulation oder das bewusste Verschweigen von Quellen widersprechen somit unseren Werten.

**Datenschutz und Vertraulichkeit**

Personenbezogene Daten und vertrauliche Informationen behandeln wir mit Sorgfalt und Diskretion. Dabei halten wir uns an die geltenden Datenschutzgesetze.

**Umgang mit KI-Werkzeugen**

Der Einsatz von KI-Tools, wie z.B. ChatGPT erfolgt transparent und verantwortungsvoll. Beiträge, die unter Nutzung solcher Hilfsmittel entstanden sind, werden eindeutig gekennzeichnet und auf Korrektheit geprüft.

# Einleitung

# Literaturübersicht

Im digitalen Zeitalter häufen sich Risiken in Bezug auf gesellschaftliches Vertrauen und Fehlinformationen in den Sozialen Medien [@kumar_feature_2024]. Die erste Studie, die wir für unsere Forschungsfrage heranziehen, kombiniert Ergebnisse aus einer Reihe von Studien von 2014 bis 2024, die sich mit der Thematik der Aufdeckung von Misinformation beschäftigen. Hieraus entwickelt die Studie, inwiefern sich Künstliche Intelligenz auf eine Abschwächung dieses Problems positiv auswirken kann und welche Entwicklungen im beobachteten Zeitraum in diesem Bereich stattgefunden haben [@kumar_feature_2024].

Diese Studie hilft uns dabei eine gute Grundlage für die Thematik zu bilden und die aktuelle Entwicklung zu visualisieren.

Der Artikel “*Blockchain for Social Good: Combating Misinformation on the Web with AI and Blockchain”* [@seneviratne_blockchain_2022] behandelt die Problematik, dass Künstliche Intelligenz sowohl zur Verbreitung von Misinformation beiträgt (z.B. durch Deepfakes), als auch zu deren Bekämpfung eingesetzt werden kann (z.B. durch Erkennungssysteme). Mithilfe von Kombination mit der Blockchain-Technologie ist es möglich Inhalte besser zu prüfen und Falschinformationen einzudämmen. Damit wird die doppelte Rolle der Künstlichen Intelligenz als Quelle und Werkzeug im Kampf gegen Misinformationen verdeutlicht [@seneviratne_blockchain_2022].

Wir ersehen es als wichtig, die Rolle von Künstlicher Intelligenz kritisch zu betrachten, auch die negative Nutzung zu erwägen und resultierend Lösungsansätze auszuarbeiten.

Unser letzter Artikel beschäftigt sich mit dem Problem, dass Falschinformationen in verschiedenen Modalitäten verbreitet werden (z.B. auch visuell, auditiv, etc.) und aktuelle KI-Modelle nach jetzigem Stande nicht ausreichend in der Lage sind Multimodale Falschinformationen zu verarbeiten. Insbesondere das Unterstreichen von falschen Informationen mit echten Bildern ohne Zusammenhang, stellt hierbei ein Problem dar. Hierfür wurde ein Machine-Learning Modell entwickelt, welches lernt mehrere Modalitäten zu analysieren und Falschinformationen zu erkennen [@saeidnia_artificial_2025].

Diese Studie weist auf mögliche, zukünftige Entwicklungsaspekte im Bereich der Künstlichen Intelligenz hin.

# Methode

## Qualitative Methode

Zur Beantwortung unserer Forschungsfrage haben wir uns für eine qualitative Methode entschieden, weil wir genauer verstehen wollten, wie Menschen über den Einsatz von Künstlicher Intelligenz gegen Misinformation denken. Besonders wichtig war uns, persönliche Meinungen, Erfahrungen und Einschätzungen zu hören. Gerade bei einem Thema wie KI, das viele Fragen aufwirft und sehr unterschiedlich wahrgenommen wird, hilft dieser Ansatz dabei, die Perspektiven möglicher Nutzer besser nachzuvollziehen.

Wir haben gezielt zwei Personen aus unserem näheren Umfeld befragt, die sich in einem unterschiedlichen Ausmaß mit dem Thema beschäftigen. Eine Person hatte persönliche Berührungspunkte mit KI im Alltag, während die andere sich intensiver im akademischen Kontext mit Fragen rund um Künstliche Intelligenz und Misinformation auseinandersetzt.

Die Interviews wurden leitfadengestützt durchgeführt und gleichzeitig mit dem Smartphone aufgezeichnet. Die Aufnahmen wurden mithilfe der Open-Source-Transkriptionssoftware Whisper transkribiert und anschließend gelöscht. Ebenso wurden die Interviewten anonymisiert.

Die Analyse erfolgte mittels thematischer Analyse der Transkripte. Wir haben die Auswertung gemeinsam und synchron durchgeführt, um eine einheitliche Interpretation der Inhalte zu gewährleisten. Auf eine spezielle Analyse-Software wurde dabei verzichtet, da der Umfang der Daten das manuelle Arbeiten ermöglichte.

## Quantitative Methode

![Studienablauf](images/PAKO_E~1.PNG){#fig-studienablauf}

Zur Untersuchung von möglichen Unterschieden zwischen evaluativer und empfehlender künstlicher Intelligenz, besonders in Bezug auf Variablen wie Workload, Genauigkeit, Vertrauen und weitere, wurde ein between-subjects-Design gewählt. Hierbei werden TeilnehmerInnen zufällig eine von den zwei KI-Varianten zugeteilt, wodurch je die Hälfte der Beantwortungen sich auf eine der KI-Varianten beziehen. Auch beinhaltet unsere Studie ein within-subject-Design, welches zuerst das Bewerten ohne und folgend mit KI-Unterstützung vorsieht. Insgesamt haben wir uns für eine Kombination aus beiden und somit zu einem Mixed Design entschieden.

Der Ablauf unserer Studie sieht zu Beginn das Ausfüllen einer Datenschutzerklärung vor. Hier wird sichergestellt, dass die TeilnehmerInnen über die Handhabung ihrer persönlichen Daten informiert werden und sie über die Datenschutzrichtlinien aufgeklärt werden. Hierauf folgt ein Pre-Test-Fragebogen, welcher die grundlegenden Merkmale unserer ProbandInnen erfragt, wie zum Beispiel das Alter. Durch diese Merkmale beziehungsweise Variablen lassen sich die Daten einordnen und analysieren. Mit einem kleinen Tutorial wird man in die kommenden Aufgaben eingeführt. Im nächsten Ablaufschritt beginnt man nun mit den Experimenten. Hier werden die TeilnehmerInnen dazu aufgefordert 10 Posts ohne die Hilfe von künstlicher Intelligenz als Misinformation oder korrekte Information zu klassifizieren. Nach der Bewertung dieser Posts folgt ein Post-Baseline-Fragebogen, um die Empfindungen der Arbeitsbelastung der zuvor ausgeführten Aufgabe festzustellen. Nun kommt es zum nächsten Experiment, wo nicht wie zuvor nur die ProbandInnen über die Bewertung der Posts entscheiden, sondern auch KI genutzt wird. Eingeteilt werden die ProbandInnen zufällig zu einer von zwei Experiment-Versionen. Die erste bezieht eine evaluierende KI ein und die zweite eine empfehlende KI. Hier durchlaufen sie wie zuvor 10 Posts und werden aufgefordert diese zu klassifizieren. Zum Abschluss der Studie füllen sie einen finalen Post-Test-Fragebogen aus, werden verabschiedet und erhalten eine kurze Danksagung für ihre Teilnahme.  

Für die Durchführung unserer Studie wurden zumal die ProbandInnen rekrutiert. Die geplante Anzahl beträgt 15 bis 20 TeilnehmerInnen, diese müssen über 18 Jahre alt sein und dürfen derzeit nicht an dem Modul SMNF an der Universität Lübeck teilnehmen. Auch sollen sie aus verschiedenen Altersbereichen stammen. Dies stellt sicher, dass die TeilnehmerInnen aus verschiedenen Bereichen und ohne spezifische Vorerfahrung aus dem Modul, unterschiedliche Einblicke in die Studie einbringen.  

Die Erhebung findet vom 24.05.2025 bis zum 02.06.2025 in Form einer Online-Umfrage statt. Durchgeführt wird diese an einem Rechner oder Tablet. 

Zur Erhebung der gesammelten Daten werden verschieden Fragebögen genutzt. Bevor das eigentliche Experiment anfängt, werden die ProbandInnen über verschiedene demographische Daten gefragt, welche verschiedene Skalen nutzen (bspw. eine nominale Skala für die Geschlechtsangabe und ordinale Skalen für die Abschlüsse der ProbandInnen). Als zweiter Teil des Pre-Test-Fragebogen werden den ProbandInnen Fragen zu ihrer interaktionsbezogenen Technikaffinität gestellt, welche eine metrische Skala nutzen [@franke_personal_2019].

Während des Experimentes müssen die ProbandInnen nun eine Falschinformation identifizieren (Ja oder nein) und das System speichert die Korrektheit der Entscheidung (Richtig oder falsch) mithilfe einer binären Skala. Außerdem werden die Reaktionszeit und Trefferquote des zweiten Tasks in einer metrischen Skala gemessen. 

Nach dem Baseline-Experiment (ohne KI-Unterstützung) sowie nach dem Durchlauf mit KI-Unterstützung werden die ProbandInnen nach ihrer Beanspruchung in verschiedenen Bereichen gefragt. Dies wird im Rahmen einer metrischen Skala gespeichert [@grippenkoven_dlr-wat_2018]. Zusätzlich wird nach dem zweiten Durchlauf auch mithilfe einer metrischen Skala abgefragt, wie viel die ProbandInnen über die Informationsverarbeitung des Systems wissen und wie sie es einschätzen können [@schrills_subjective_2021].

Als nächstes wird abgefragt, wie vertrauensvoll und verlässlich die KI bzw. das System wahrgenommen wird [@madsen_measuring_2000]. Zusätzlich werden allgemeine Fragen zur Wahrnehmung des Systems gestellt [@laugwitz_construction_2008] Beide Fragebögen nutzen die metrische Skala. 

Und zuletzt sollen die ProbandInnen die allgemeine Gebrauchstauglichkeit des Systems bewerten mithilfe einer metrischen System Usability Scale [@gao_multi-language_2020].

Die Analyse der Daten erfolgt bei dieser Studie anhand von t-Tests und Korrelation. Der t-Test überprüft, ob es einen signifikanten Unterschied zwischen den Mittelwerten von zwei Gruppen gibt. Dies bietet sich besonders zwischen den Variablen „Systemtyp“, also die Nutzung von einer der beiden KI-Versionen oder ohne KI, und der Variable „Ergebnis“. Wir untersuchen also, wie die Korrektheit der Antworten der ProbandInnen von der Nutzung eines KI-Modells anhängig ist. 

Mit der Korrelation lässt sich die lineare Beziehung zwischen zwei Variablen ermitteln. Für diese analysieren wir die Werte der unabhängigen Variable „Alter“ in Bezug zu der abhängigen Variable „Perceived Reliability“, welche das Vertrauen in KI repräsentiert [@madsen_measuring_2000]. Hiermit untersuchen wir, ob das Vertrauen in KI sich abhängig vom Alter unterscheidet. 

# Ergebnisse

## Qualitative Ergebnisse

Für die Interviews haben wir insgesamt zwei NutzerInnen befragt und die Interviews dann analysiert. Dabei haben wir darauf geachtet, Personen mit unterschiedlichen Perspektiven und Vorkenntnissen auszuwählen. Eine Person hat sich selbst bereits mit diesem Thema im akademischen Kontext befasst und die andere Person nutzt KI manchmal in ihrem Alltag, hat desweiteren aber keine spezifischen Kenntnisse.

| Name | Definition | Textstelle |
|------------------------|------------------------|------------------------|
| \[T1\] KI-Skepsis | Viele NutzerInnen vertrauen KI nur bedingt, da sie auch fehlerhaft ist und NutzerInnen die Funktionweise schwer nachvolziehen können. | "Denn nicht jede Person glaubt, was die KI sagt, weil die KI auch Missinformationen verbreiten kann. \[...\] Deswegen bin ich manchmal ein bisschen skeptisch, was die KI auch selbst von sich gibt." (A5_1, Zeile 107-110) |
| \[T2\] Vereinfachte Darstellung | Um den Überblick behalten zu können, sollten die Antworten der KI in Stichpunkten oder kurzen Absätzen passieren. | "Dass man einen Überblick hat über die Informationen, die man da gerade kriegt." (A5_2, Zeile 168-169) |
| \[T3\] Kontrolle über die Nutzung | Die NutzerInnen sollen selbst entscheiden können, wann und in welchen Umfang sie die KI nutzen. | "Ich bin eher dafür, die Möglichkeit zu haben, es an- und auszuschalten, da ich der Meinung bin, dass jeder seine eigenen Präferenzen hat und es auch Leute gibt, die nicht KI nutzen möchten \[...\]." (A5_1, Zeile 223-225) |

: Thematische Analyse {#tbl-thematische-analyse}

Für die Interviews haben wir insgesamt zwei NutzerInnen befragt und die Interviews dann analysiert. Dabei haben wir darauf geachtet, Personen mit unterschiedlichen Perspektiven und Vorkenntnissen auszuwählen. Eine Person hat sich selbst bereits mit diesem Thema im akademischen Kontext befasst und die andere Person nutzt KI manchmal in ihrem Alltag, hat des weiteren aber keine spezifischen Kenntnisse.

Beide Probanden haben Bedenken zur Glaubwürdigkeit der Aussagen der KI \[T1\] geäußert, besonders wenn es um Belegung der Aussagen durch entsprechende Quellen geht.

Dies ist das Resultat aus vorherigen Erfahrungen mit KI. In diesen Fällen gab ihnen KI falsche Antworten und verbreitete somit selbst Missinformationen: „Da kann es aber nämlich auch passieren, dass es dann vielleicht auch falsche Quellen mit rein nimmt. Und dass dadurch dann auch die Antwort verfälscht wird.“ (A5_2, Zeile 62-64) Daraus folgt also die Skepsis zur weiteren Nutzung von KI.

Als Lösungsansatz nannte eine Person A5_1 eine hohe Transparenz der KI: „Man muss wissen, woher die KI ihre Quellen hat, ihre Belege, ihre Beispiele oder auch aus welchen Quellen ihre Aussage kommt. Das ist auf jeden Fall sehr wichtig, damit die Richtigkeit der Aussagen wirklich belegt werden kann.“ (A5_1, Zeile 118-122)

In beiden Interviews wurde die Wichtigkeit, einen guten Überblick \[T2\] behalten zu können, hervorgehoben. Die Antworten der künstlichen Intelligenz sollen möglichst kurz und präzise in Textformat dargestellt werden, beispielsweise in Stichpunkten oder auch kurzen Absätzen. „\[…\] wenn es ein langer Paragraph ist, dann bitte mit vorgehobenen Wörtern, weil es sich einfach einfacher beim Lesen macht und ich bevorzuge einfach Stichpunkte.“ (A5­\_1, Zeile 244-246) So gewährleistet man, dass die NutzerInnen die Informationsmenge gut verarbeiten können und das Interagieren mit der KI als angenehm empfunden wird.

Unsere ProbandInnen betonen zudem, dass die NutzerInnen selbst entscheiden können sollen, wann und wie sie die KI nutzen wollen \[T3\]. Die persönlichen Präferenzen sind unterschiedlich und es ist wichtig, diese im Rahmen der KI zu beachten. Eine Person betont hier aber auch den Gegenfall, wenn die KI eben nicht immer automatisch aktiviert ist: „ \[…\] aber würde man ja auch die Missinformation halt sehen und vielleicht auch denken, dass es wahr ist und das glauben.“ (A5_2, Zeile 153-155)

## Quantitative Ergebnisse

```{r echo=FALSE, message=FALSE}

library(dplyr)
library(ggplot2)
library(tidyverse)
library(psych)
library(gt)
library(tinytex)

study_data <- read.csv("C:/Users/linni/Documents/Statistik-Gruppe-A5/2025-06-10/open/data_combined.csv", header = TRUE, sep = ",", fill = TRUE)

records_count_decision_correct_rate_E <- sum(!is.na(study_data$decision_correct_rate_E))
records_count_decision_correct_rate_R <- sum(!is.na(study_data$decision_correct_rate_R))
records_count_age <- sum(!is.na(study_data$age))
records_count_hct_r01 <- sum(!is.na(study_data$hct_r01))

age_evaluation <- study_data$age
mean_age <- mean(age_evaluation, na.rm = TRUE)
median_age <- median(age_evaluation, na.rm = TRUE)
min_age <- min(age_evaluation, na.rm = TRUE)
max_age <- max(age_evaluation, na.rm = TRUE)
sd_age <- sd(age_evaluation, na.rm = TRUE)

keys <- list(hct = c("hct_r01", "hct_r02", "hct_r03", "hct_r04", "hct_r05"))
scored <- psych::scoreItems(keys, study_data)
surveydata <- data.frame(hct = scored$scores)
surveydata$age <- study_data$age

hct_evaluation <- surveydata$hct
mean_hct <- mean(hct_evaluation, na.rm = TRUE)
median_hct <- median(hct_evaluation, na.rm = TRUE)
min_hct <- min(hct_evaluation, na.rm = TRUE)
max_hct <- max(hct_evaluation, na.rm = TRUE)
sd_hct <- sd(hct_evaluation, na.rm = TRUE)


frequencies_decision_correct_rate_E <- table(round(study_data$decision_correct_rate_E, 1), useNA = "no")
frequencies_decision_correct_rate_R <- table(round(study_data$decision_correct_rate_R, 1), useNA = "no")

#procent_decision_correct_rate_E <- prop.table(frequencies_decision_correct_rate_E)
#procent_decision_correct_rate_R <- prop.table(frequencies_decision_correct_rate_R)

#all_categories <- sort(unique(c(names(procent_decision_correct_rate_E),
#                                names(procent_decision_correct_rate_R))))

#categorical_data_table <- data.frame(
#  Variable = c("Anteil richtige Antworten - Evaluatives KI-Modell", "Anteil richtige Antworten - Empfehlendes KI-Modell"), 
#  matrix(0, nrow = 2, ncol = length(all_categories))
#)
#colnames(categorical_data_table)[-1] <- all_categories
#
#categorical_data_table[1, -1] <- procent_decision_correct_rate_E[all_categories]
#categorical_data_table[2, -1] <- procent_decision_correct_rate_R[all_categories]
#
#categorical_data_table[is.na(categorical_data_table)] <- 0


#categorical_data_table %>%
#  gt() %>%
#  fmt_percent(
#    columns = where(is.numeric),
#    decimals = 1
#  ) %>%
#  tab_header(
#    title = "Antwortverteilung",
#    subtitle = "Kategoriale Variablen"
#  )

mean_frequencies_decision_correct_rate_E <- mean(frequencies_decision_correct_rate_E, na.rm = TRUE)
median_frequencies_decision_correct_rate_E <- median(frequencies_decision_correct_rate_E, na.rm = TRUE)
min_frequencies_decision_correct_rate_E <- min(frequencies_decision_correct_rate_E, na.rm = TRUE)
max_frequencies_decision_correct_rate_E <- max(frequencies_decision_correct_rate_E, na.rm = TRUE)
sd_frequencies_decision_correct_rate_E <- sd(frequencies_decision_correct_rate_E, na.rm = TRUE)

mean_frequencies_decision_correct_rate_R <- mean(frequencies_decision_correct_rate_R, na.rm = TRUE)
median_frequencies_decision_correct_rate_R <- median(frequencies_decision_correct_rate_R, na.rm = TRUE)
min_frequencies_decision_correct_rate_R <- min(frequencies_decision_correct_rate_R, na.rm = TRUE)
max_frequencies_decision_correct_rate_R <- max(frequencies_decision_correct_rate_R, na.rm = TRUE)
sd_frequencies_decision_correct_rate_R <- sd(frequencies_decision_correct_rate_R, na.rm = TRUE)

decision_correct_R_data <- data.frame(decision_correct_rate_R = study_data$decision_correct_rate_R)
decision_correct_R_data <- decision_correct_R_data[!is.na(decision_correct_R_data$decision_correct_rate_R), , drop = FALSE]
decision_correct_E_data <- data.frame(decision_correct_rate_E = study_data$decision_correct_rate_E)
decision_correct_E_data <- decision_correct_E_data[!is.na(decision_correct_E_data$decision_correct_rate_E), , drop = FALSE]
```

**Stichprobe**

Für unsere Studie zum Thema KI als Hilfsmittel zur Detektion von Misinformationen haben wir die Daten von diversen ProbandInnen (*N* = 176) gesammelt. Davon waren insgesamt 84 ProbandInnen männlich und 90 weiblich. Des Weiteren beinhaltet die Studie eine diverse und eine non-binary teilnehmende Person.

Ebenso können die ProbandInnen anhand ihres Alters differenziert werden. Hierbei ergab sich eine Altersspanne von 18 (Mindestalter zur Teilnahme an der Studie) bis 69 Jahren. Aus diesen Daten folgt ein Durchschnittsalter von *M* = 25.9 Jahren mit einer Standardabweichung von *SD* = 10.6 Jahren. Darüber hinaus liegt der Median bei *Mdn* = 22 Jahren.

Bei der Auswertung unserer gesammelten Daten haben wir uns mit der Abhängigkeit von Alter und Vertrauen in KI beschäftigt. Vor diesem Hintergrund haben wir unseren Fokus nicht auf das Geschlecht, sondern primär auf das Alter der ProbandInnen gelegt und somit die gesamte Altersspanne betrachtet.

Die Generalisierbarkeit können wir, da wir uns größtenteils auf die Eigenschaft Alter fokussieren, auch nur für den Bereich einschätzen. Wir vermuten, dass unsere Studie generalisiert werden kann, da unsere Altersspanne so weit ist.

**Deskriptive Statistik**

```{r echo=FALSE, message=FALSE}
#| label: tbl-anteil-richtiger-antworten
#| tbl-cap: "Statistische Kennzahlen der Variablen des t-Tests"

metric_data_table <- data.frame(
  Variable = c("Anteil richtiger Antworten - Evaluatives KI-Modell", "Anteil richtiger Antworten - Empfehlendes KI-Modell"),
  N = format(c(records_count_decision_correct_rate_E, records_count_decision_correct_rate_R), nsmall = 0),
  M = c(mean_frequencies_decision_correct_rate_E, mean_frequencies_decision_correct_rate_R),
  Mdn = c(median_frequencies_decision_correct_rate_E, median_frequencies_decision_correct_rate_R),
  Min = c(min_frequencies_decision_correct_rate_E, min_frequencies_decision_correct_rate_R),
  Max = c(max_frequencies_decision_correct_rate_E, max_frequencies_decision_correct_rate_R),
  SD = c(sd_frequencies_decision_correct_rate_E, sd_frequencies_decision_correct_rate_R)
  )

metric_data_table %>%
  gt() %>%
  fmt_number(columns = where(is.numeric), decimals = 2)
```

```{r echo=FALSE, message=FALSE}
#| label: tbl-alter-und-vertrauen
#| tbl-cap: "Statistische Kennzahlen der Variablen der Korrelation"

metric_data_table <- data.frame(
  Variable = c("Alter", "Vertrauen ins System"),
  N = format(c(records_count_age, records_count_hct_r01), nsmall = 0),
  M = c(mean_age, mean_hct),
  Mdn = c(median_age, median_hct),
  Min = c(min_age, min_hct),
  Max = c(max_age, max_hct),
  SD = c(sd_age, sd_hct)
  )

metric_data_table %>%
  gt() %>%
  fmt_number(columns = where(is.numeric), decimals = 2)
```

Für unsere Studie haben wir mehrere Variablen benutzt, um unsere Forschungsfragen beantworten zu können. Diese sind “Korrektheit/Ergebnis” und “Systemtyp” im Zusammenhang miteinander, außerdem “Alter” im Zusammenhang zu “Vertrauen ins System”. Die metrische Variable “Korrektheit/Ergebnis” befasst sich damit, ob beim Identifizieren der Missinformationen richtig entschieden wurde.

Die damit verbundene Variable “Systemtyp” umfasst zwei verschiedene KI-Modelle. Diese sind evaluativ (E) und empfehlend (R). Der Mittelwert liegt beim evaluativen Modell *M* = 0.765 und beim empfehlenden Modell bei *M* = 0.767.

Die metrische Variable “Alter” umfasst das Alter aller ProbandInnen in Jahren. Die Teilnehmenden waren zwischen 18 und 69 Jahre alt. Der Mittelwert lag bei *M* = 25.9, mit einer Standardabweichung von *SD* = 10.6, was auf eine relativ junge, aber dennoch heterogene Stichprobe hinweist.

Unsere letzte Variable, die wir betrachtet haben, ist “Vertrauen ins System”. Dabei geht es darum wie viel Vertrauen die ProbandInnen in KI-Systeme haben, um Missinformationen im Netzt zu detektieren und auszusortieren.

**Inferenzstatistik**

```{r echo=FALSE, message=FALSE}

result_ttest <- t.test(decision_correct_R_data$decision_correct_rate_R, decision_correct_E_data$decision_correct_rate_E, var.equal = TRUE)
print(result_ttest)

result_correct_rate <- data.frame(
  value = c(decision_correct_R_data$decision_correct_rate_R, decision_correct_E_data$decision_correct_rate_E),
  group = rep(c("R", "E"), times = c(length(decision_correct_R_data$decision_correct_rate_R), length(decision_correct_E_data$decision_correct_rate_E)))
) %>%
  filter(!is.na(value))

summary_stats <- result_correct_rate %>%
  group_by(group) %>%
  summarise(
    mean = mean(value),
    sd = sd(value),
    n = n(),
    se = sd / sqrt(n),
    .groups = "drop"
  )
```

```{r echo=FALSE, message=FALSE}
#| label: fig-ttest
#| fig-cap: "t-Test: KI-System und Korrektheit"

ggplot(summary_stats, aes(x = group, y = mean)) +
  geom_point(size = 4, color = "blue") +
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), width = 0.2) +
  labs(
    x = "Gruppe",
    y = "Durchschnitt"
  )
```

Die Analyse erfolgte mittels eines unverbundenen T-Tests. Dabei haben wir untersucht, ob es innerhalb der Variable “Systemtyp” einen Unterschied in der Erfolgsquote bei der Aufdeckung von Missinformationen zwischen dem Evaluativen (E) und dem Empfehlenden (R) KI-System gibt. Dabei haben wir uns die Daten aller 176 ProbandInnen angeschaut.

In der folgenden sieht man die aus der Studie ergebenen Werte, welche wir im Folgenden weiter analysiert haben.

Aus unseren Daten ergibt sich, dass beide Modelle ähnlich gut funktioniert haben. Die Differenz der durchschnittlichen Korrektheit des evaluativen Modells (*M* = 0.76, *SD* = 0.16) und des empfehlenden Modells (*M* = 0.76, *SD* = 0.14) war nicht signifikant (*t*(174) = -0.08, *p* \> .05).

```{r echo=FALSE, message=FALSE}
cor_age_hct_r_all <- cor(surveydata$age, surveydata$hct, use = "complete.obs", method = "pearson")

cor.test(surveydata$age, surveydata$hct, use = "complete.obs", method = "pearson")

```

```{r echo=FALSE, message=FALSE}
#| label: fig-korrelation
#| fig-cap: "Korrelation: Alter und Vertrauen in das System"

ggplot(surveydata, aes(x = age, y = hct)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") + 
  labs(
  x = "Alter",
  y = "Vertrauen ins System"
)
```

Bei der Korrelationsanalyse haben wir uns, wie zuvor erwähnt, für die Variablen “Age” in Korrelation zu “Vertrauen in Umgang mit KI” entschieden. Auch hier haben wir uns die Daten aller 176 ProbandInnen angeschaut, um eine möglichst große Altersspanne zu haben. In der folgenden Abbildung 2 sieht man die aus der Studie folgenden Werte, welche wir anschließend analysiert haben.

Abbildung 2 stellt den Zusammenhang zwischen Age und Human-Computer-Trust dar.

Aus unseren Daten ergibt sich, dass es zwar eine kleine Abnahme an Vertrauen in die KI gibt, je älter die ProbandInnen sind, jedoch reichen die Daten nicht aus, um einen eindeutigen Zusammenhang zwischen den beiden Variablen zu identifizieren. Es besteht also kein Zusammenhang zwischen dem Alter und dem Vertrauen in die Nutzung von KI (*r*(174) = -0.132 , *p* = .080). Das bedeutet, dass ein höheres Alter nicht direkt mit einem geringeren Vertrauen in die KI einhergeht.

# Diskussion

## Literaturverzeichnis

::: {#refs}
:::

## Anhang 1 - Rekrutierungstext

TeilnehmerInnen für KI-Studie gesucht!

Für unsere Studie zum Thema KI-Unterstützungssysteme als Hilfsmittel zur Erkennung von Falschinformationen suchen wir ProbandInnen. Dabei untersuchen wir den Umgang mit solchen KI-Unterstützungssysteme

Einschlusskriterien sind:

Du bist mindestens 18 Jahre alt

Du nimmst derzeit nicht am Modul Statistik und Methoden der Nutzenden-Forschung an der Uni Lübeck teil

Du hast einen Laptop/PC oder Tablet, an dem du die online Studie ausfüllen kannst

Die Teilnahme dauert ca. 45-60 Minuten und erfolgt online. Alle Daten werden anonym behandelt.

Interesse geweckt? Dann nimm jetzt über folgenden Link teil: <https://dsslab.hciuse.sh/study/pilot?groupId=gr-a5>

Vielen Dank für deine Unterstützung!

Linnea, Sophie, Mel, Lina und Eric
