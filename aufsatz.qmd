---
title: "Living Document"
date: today
author: "Melina Esen, Eric Ansorge, Sophie Spektor, Lina Woeste und Linnea Lund"
format:
    html: default
    pdf: default
papersize: "a4"
number-sections: true
number-depth: 1
fontsize: "12"
editor: visual
bibliography: references.bib
csl: apa.csl
style: "american-psychological-association"
---

**GitHub Repository:** https://github.com/linnealund/SMNF-Gruppe-A5

**Für die Abgabe aktueller GitHub Hash:** SOME_HASH

## **Code of Conduct**

Im Rahmen unserer Zusammenarbeit als Projektgruppe halten wir einen Verhaltenskodex ein, der wie folgt definiert ist:

**Umgang mit Feedback und Meinungsverschiedenheiten**

Wir begegnen Meinungsverschiedenheiten stets offen und ermutigen kritisches Denken. Jeder soll die Möglichkeit haben Bedenken, Gedanken und Meinungen frei äußern zu dürfen, ohne dafür diskriminiert zu werden. Dabei legen wir Wert auf konstruktives Feedback.

**Faire Aufteilung der Arbeitslast**

Die Einzelnen Aufgaben werden gleichmäßig verteilt, so dass jeder ähnlich viel machen muss. Dabei achten wir auf Stärken und Schwächen jedes einzelnen und gehen bei der Verteilung auf diese ein.

**Verhalten in Bezug auf vereinbarte und verpflichtende Termine**

Jeder hat die Verantwortung vereinbarte Termine wahrzunehmen. Sollte es aus Gründen dazu kommen, dass besagter Termin nicht wahrgenommen werden kann, so muss rechtzeitig Bescheid gegeben werden. So kann den anderen Mitgliedern eine Umplanung ermöglicht werden.

**Wissenschaftliche Integrität**

Wir halten uns an die Grundsätze guten wissenschaftlichen Arbeitens. Dazu gehören Ehrlichkeit, Genauigkeit, Objektivität sowie der verantwortungsvolle Umgang mit Daten und Quellen. Plagiate, Datenmanipulation oder das bewusste Verschweigen von Quellen widersprechen somit unseren Werten.

**Datenschutz und Vertraulichkeit**

Personenbezogene Daten und vertrauliche Informationen behandeln wir mit Sorgfalt und Diskretion. Dabei halten wir uns an die geltenden Datenschutzgesetze.

**Umgang mit KI-Werkzeugen**

Der Einsatz von KI-Tools, wie z.B. ChatGPT erfolgt transparent und verantwortungsvoll. Beiträge, die unter Nutzung solcher Hilfsmittel entstanden sind, werden eindeutig gekennzeichnet und auf Korrektheit geprüft.

# Einleitung

# Literaturübersicht

Im digitalen Zeitalter häufen sich Risiken in Bezug auf gesellschaftliches Vertrauen und Fehlinformationen in den Sozialen Medien [@kumar_feature_2024]. Die erste Studie, die wir für unsere Forschungsfrage heranziehen, kombiniert Ergebnisse aus einer Reihe von Studien von 2014 bis 2024, die sich mit der Thematik der Aufdeckung von Misinformation beschäftigen. Hieraus entwickelt die Studie, inwiefern sich Künstliche Intelligenz auf eine Abschwächung dieses Problems positiv auswirken kann und welche Entwicklungen im beobachteten Zeitraum in diesem Bereich stattgefunden haben [@kumar_feature_2024].

Diese Studie hilft uns dabei eine gute Grundlage für die Thematik zu bilden und die aktuelle Entwicklung zu visualisieren.

Der Artikel “*Blockchain for Social Good: Combating Misinformation on the Web with AI and Blockchain”* [@seneviratne_blockchain_2022] behandelt die Problematik, dass Künstliche Intelligenz sowohl zur Verbreitung von Misinformation beiträgt (z.B. durch Deepfakes), als auch zu deren Bekämpfung eingesetzt werden kann (z.B. durch Erkennungssysteme). Mithilfe von Kombination mit der Blockchain-Technologie ist es möglich Inhalte besser zu prüfen und Falschinformationen einzudämmen. Damit wird die doppelte Rolle der Künstlichen Intelligenz als Quelle und Werkzeug im Kampf gegen Misinformationen verdeutlicht [@seneviratne_blockchain_2022].

Wir ersehen es als wichtig, die Rolle von Künstlicher Intelligenz kritisch zu betrachten, auch die negative Nutzung zu erwägen und resultierend Lösungsansätze auszuarbeiten.

Unser letzter Artikel beschäftigt sich mit dem Problem, dass Falschinformationen in verschiedenen Modalitäten verbreitet werden (z.B. auch visuell, auditiv, etc.) und aktuelle KI-Modelle nach jetzigem Stande nicht ausreichend in der Lage sind Multimodale Falschinformationen zu verarbeiten. Insbesondere das Unterstreichen von falschen Informationen mit echten Bildern ohne Zusammenhang, stellt hierbei ein Problem dar. Hierfür wurde ein Machine-Learning Modell entwickelt, welches lernt mehrere Modalitäten zu analysieren und Falschinformationen zu erkennen [@saeidnia_artificial_2025].

Diese Studie weist auf mögliche, zukünftige Entwicklungsaspekte im Bereich der Künstlichen Intelligenz hin.

# Methode

## Qualitative Methode

Zur Beantwortung unserer Forschungsfrage haben wir uns für eine qualitative Methode entschieden, weil wir genauer verstehen wollten, wie Menschen über den Einsatz von Künstlicher Intelligenz gegen Misinformation denken. Besonders wichtig war uns, persönliche Meinungen, Erfahrungen und Einschätzungen zu hören. Gerade bei einem Thema wie KI, das viele Fragen aufwirft und sehr unterschiedlich wahrgenommen wird, hilft dieser Ansatz dabei, die Perspektiven möglicher Nutzer besser nachzuvollziehen.

Wir haben gezielt zwei Personen aus unserem näheren Umfeld befragt, die sich in einem unterschiedlichen Ausmaß mit dem Thema beschäftigen. Eine Person hatte persönliche Berührungspunkte mit KI im Alltag, während die andere sich intensiver im akademischen Kontext mit Fragen rund um Künstliche Intelligenz und Misinformation auseinandersetzt.

Die Interviews wurden leitfadengestützt durchgeführt und gleichzeitig mit dem Smartphone aufgezeichnet. Die Aufnahmen wurden mithilfe der Open-Source-Transkriptionssoftware Whisper transkribiert und anschließend gelöscht. Ebenso wurden die Interviewten anonymisiert.

Die Analyse erfolgte mittels thematischer Analyse der Transkripte. Wir haben die Auswertung gemeinsam und synchron durchgeführt, um eine einheitliche Interpretation der Inhalte zu gewährleisten. Auf eine spezielle Analyse-Software wurde dabei verzichtet, da der Umfang der Daten das manuelle Arbeiten ermöglichte.

# Ergebnisse

## Qualitative Ergebnisse

Für die Interviews haben wir insgesamt zwei NutzerInnen befragt und die Interviews dann analysiert. Dabei haben wir darauf geachtet, Personen mit unterschiedlichen Perspektiven und Vorkenntnissen auszuwählen. Eine Person hat sich selbst bereits mit diesem Thema im akademischen Kontext befasst und die andere Person nutzt KI manchmal in ihrem Alltag, hat desweiteren aber keine spezifischen Kenntnisse.

| Name | Definition | Textstelle |
|-----------------|----------------------------|----------------------------|
| \[T1\] KI-Skeptik | Viele NutzerInnen vertrauen KI nur bedingt, da sie auch fehlerhaft ist und NutzerInnen die Funktionweise schwer nachvolziehen können. | "Denn nicht jede Person glaubt, was die KI sagt, weil die KI auch Missinformationen verbreiten kann. \[...\] Deswegen bin ich manchmal ein bisschen skeptisch, was die KI auch selbst von sich gibt." (A5_1, Zeile 107-110) |
| \[T2\] Vereinfachte Darstellung | Um den Überblick behalten zu können, sollten die Antworten der KI in Stichpunkten oder kurzen Absätzen passieren. | "Dass man einen Überblick hat über die Informationen, die man da gerade kriegt. Genau und nicht, dass Information auf einmal erschlagen wird, weil das so viel ist." (A5_2, Zeile 168-171) |
| \[T3\] Kontrolle über die Nutzung | Die NutzerInnen sollen selbst entscheiden können, wann und in welchen Umfang sie die KI nutzen. | "Ich bin eher dafür, die Möglichkeit zu haben, es an- und auszuschalten, da ich der Meinung bin, dass jeder seine eigenen Preferenzen hat und es auch Leute gibt, die nicht KI nutzen möchten \[...\]." (A5_1, Zeile 223-225) |

... (Erläuterung der Ergebnisse aus der Tabelle)

# Diskussion

## Literaturverzeichnis
