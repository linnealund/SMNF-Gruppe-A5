
@article{saeidnia_artificial_2025,
	title = {Artificial intelligence in the battle against disinformation and misinformation: a systematic review of challenges and approaches},
	volume = {67},
	issn = {0219-3116},
	url = {https://doi.org/10.1007/s10115-024-02337-7},
	doi = {10.1007/s10115-024-02337-7},
	shorttitle = {Artificial intelligence in the battle against disinformation and misinformation},
	abstract = {In the rapidly evolving digital age, the proliferation of disinformation and misinformation poses significant challenges to societal trust and information integrity. Recognizing the urgency of addressing this issue, this systematic review endeavors to explore the role of artificial intelligence ({AI}) in combating the spread of false information. This study aims to provide a comprehensive analysis of how {AI} technologies have been utilized from 2014 to 2024 to detect, analyze, and mitigate the impact of misinformation across various platforms. This research utilized an exhaustive search across prominent databases such as {ProQuest}, {IEEE} Explore, Web of Science, and Scopus. Articles published within the specified timeframe were meticulously screened, resulting in the identification of 8103 studies. Through elimination of duplicates and screening based on title, abstract, and full-text review, we meticulously distilled this vast pool to 76 studies that met the study’s eligibility criteria. Key findings from the review emphasize the advancements and challenges in {AI} applications for combating misinformation. These findings highlight {AI}’s capacity to enhance information verification through sophisticated algorithms and natural language processing. They further emphasize the integration of human oversight and continual algorithm refinement emerges as pivotal in augmenting {AI}’s effectiveness in discerning and countering misinformation. By fostering collaboration across sectors and leveraging the insights gleaned from this study, researchers can propel the development of ethical and effective {AI} solutions.},
	pages = {3139--3158},
	number = {4},
	journaltitle = {Knowledge and Information Systems},
	shortjournal = {Knowl Inf Syst},
	author = {Saeidnia, Hamid Reza and Hosseini, Elaheh and Lund, Brady and Tehrani, Maral Alipour and Zaker, Sanaz and Molaei, Saba},
	urldate = {2025-05-05},
	date = {2025-04-01},
	langid = {english},
	keywords = {Misinformation, Artificial intelligence, Artificial Intelligence, Disinformation, Review},
	file = {Full Text PDF:C\:\\Users\\linni\\Zotero\\storage\\LTHIDCRN\\Saeidnia et al. - 2025 - Artificial intelligence in the battle against disinformation and misinformation a systematic review.pdf:application/pdf},
}

@article{kumar_feature_2024,
	title = {Feature importance in the age of explainable {AI}: Case study of detecting fake news \& misinformation via a multi-modal framework},
	volume = {317},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221723007609},
	doi = {10.1016/j.ejor.2023.10.003},
	shorttitle = {Feature importance in the age of explainable {AI}},
	abstract = {In recent years, fake news has become a global phenomenon due to its explosive growth and ability to leverage multimedia content to manipulate user opinions. Fake news is created by manipulating images, text, audio, and videos, particularly on social media, and the proliferation of such disinformation can trigger detrimental societal effects. False forwarded messages can have a devastating impact on society, spreading propaganda, inciting violence, manipulating public opinion, and even influencing elections. A major shortcoming of existing fake news detection methods is their inability to simultaneously learn and extract features from two modalities and train models with shared representations of multimodal (textual and visual) information. Feature engineering is a critical task in the fake news detection model's machine learning ({ML}) development process. For {ML} models to be explainable and trusted, feature engineering should describe how many features used in the {ML} models contribute to making more accurate predictions. Feature engineering, which plays an important role in the development of an explainable {AI} system by shaping the features used in the {ML} models, is an interconnected concept with explainable {AI} as it affects the model's interpretability. In the research, we develop a fake news detector model in which we (1) identify several textual and visual features that are associated with fake or credible news; specifically, we extract features from article titles, contents, and, top images; (2) investigate the role of all multimodal features (content, emotions and manipulation-based) and combine the cumulative effects using the feature engineering that represent the behavior of fake news propagators; and (3) develop a model to detect disinformation on benchmark multimodal datasets consisting of text and images. We conduct experiments on several real-world multimodal fake news datasets, and our results show that on average, our model outperforms existing single-modality methods by large margins that do not use any feature optimization techniques.},
	pages = {401--413},
	number = {2},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Kumar, Ajay and Taylor, James W.},
	urldate = {2025-05-05},
	date = {2024-09-01},
	keywords = {Analytics, Explainable data analytics, Feature selection, Machine learning, Optimization algorithm},
	file = {PDF:C\:\\Users\\linni\\Zotero\\storage\\X3WZCCCT\\Kumar und Taylor - 2024 - Feature importance in the age of explainable AI Case study of detecting fake news & misinformation.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\linni\\Zotero\\storage\\3R3SWGNB\\S0377221723007609.html:text/html},
}

@inproceedings{seneviratne_blockchain_2022,
	location = {Barcelona Spain},
	title = {Blockchain for Social Good: Combating Misinformation on the Web with {AI} and Blockchain},
	isbn = {978-1-4503-9191-7},
	url = {https://dl.acm.org/doi/10.1145/3501247.3539016},
	doi = {10.1145/3501247.3539016},
	shorttitle = {Blockchain for Social Good},
	abstract = {The spread of deceptive or misleading information, commonly referred to as misinformation, poses a social, economic, and political threat. Such deceptive information spreads quickly and inexpensively. For example, with the hype around blockchain technologies, misinformation on “get rich quick” scams on the Web is rampant, as evidenced by sophisticated Twitter hacks of celebrities and many social media posts that bait unsuspecting users to visit phishing websites. Unfortunately, {AI} technologies have contributed to the growing pains of misinformation on the Web, with the advances in technologies such as generative adversarial deep learning techniques that can generate “deep fakes” for nefarious purposes. At the same time, researchers are working on a different set of {AI} technologies to combat misinformation, akin to “fighting fire with fire.” As there is no clear way to win the online “cat-and-mouse” game against fake news generators and spreaders of misinformation, we believe social media platforms could be fortified with blockchain and {AI} technologies to mitigate the extent of misinformation propagation in various communities worldwide. Tamperproof blockchain techniques can provide irrefutable evidence of what content is authentic, guaranteeing how the information has evolved with provenance trails. Various {AI} models that could be used for detecting fake news can be served on a blockchain for the effective and transparent utility of the model. Such a synergistic combination of {AI} and blockchain is a burgeoning area of research. This paper outlines a proposal for combining blockchain and {AI} techniques for handling misinformation on the Web and highlights some of the early ongoing work in this space.},
	eventtitle = {{WebSci} '22: 14th {ACM} Web Science Conference 2022},
	pages = {435--442},
	booktitle = {14th {ACM} Web Science Conference 2022},
	publisher = {{ACM}},
	author = {Seneviratne, Oshani},
	urldate = {2025-05-05},
	date = {2022-06-26},
	langid = {english},
	file = {PDF:C\:\\Users\\linni\\Zotero\\storage\\5XA5UMVR\\Seneviratne - 2022 - Blockchain for Social Good Combating Misinformation on the Web with AI and Blockchain.pdf:application/pdf},
}

@article{franke_personal_2019,
	title = {A personal resource for technology interaction: Development and validation of the Affinity for Technology Interaction ({ATI}) scale},
	volume = {35},
	issn = {1532-7590},
	doi = {10.1080/10447318.2018.1456150},
	shorttitle = {A personal resource for technology interaction},
	abstract = {Successful coping with technology is relevant for mastering daily life. Based on related conceptions, we propose affinity for technology interaction ({ATI}), defined as the tendency to actively engage in intensive technology interaction, as a key personal resource for coping with technology. We present the 9-item {ATI} scale, an economical unidimensional scale that assesses {ATI} as an interaction style rooted in the construct need for cognition ({NFC}). Results of multiple studies (n {\textgreater} 1500) showed that the scale achieves good to excellent reliability, exhibits expected moderate to high correlations with geekism, technology enthusiasm, {NFC}, self-reported success in technical problem-solving and technical system learning success, and also with usage of technical systems. Further, correlations of {ATI} with the Big Five personality dimensions were weak at most. Based on the results, the {ATI} scale appears to be a promising tool for research applications such as the characterization of user diversity in system usability tests and the construction of general models of user-technology interaction. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {456--467},
	number = {6},
	journaltitle = {International Journal of Human-Computer Interaction},
	author = {Franke, Thomas and Attig, Christiane and Wessel, Daniel},
	date = {2019},
	note = {Place: United Kingdom
Publisher: Taylor \& Francis},
	keywords = {Adult Attitudes, Attitude Measures, Rating Scales, Technology, Test Construction, Test Validity},
	file = {Snapshot:C\:\\Users\\linni\\Zotero\\storage\\QDKQTF3V\\2019-10130-002.html:text/html},
}

@book{grippenkoven_dlr-wat_2018,
	title = {{DLR}-{WAT}: Ein Instrument zur Untersuchung des optimalen Beanspruchungsniveaus in hochautomatisierten Mensch-Maschine-Systemen},
	shorttitle = {{DLR}-{WAT}},
	abstract = {In diesem Artikel wird das „{DLR} - Workload Assessment Tool“ ({DLR}–{WAT}) vorgestellt, ein Fragebogen zur Selbsteinschätzung der Beanspruchung, der gezielter als bestehende Messwerkzeuge wie z.B. der {NASA}-{TLX} Abweichungen von einem subjektiven Optimum der Beanspruchung berücksichtigt. Automatisierung und Digitalisierung sind derzeit die bestimmenden Trends im Personen- und Güterverkehr. Ob auf der Straße, der Schiene oder in der Luft, die Rolle des Menschen im Verkehr wandelt sich im Angesicht dieser Entwicklungen rapide. Technische Assistenzen unterstützen den Menschen und hochautomatisierte Systeme übernehmen in einzelnen Bereichen bereits Aufgaben des Menschen wie z.B. die Steuerung und Navigation. Die aktive Rolle des Menschen, zum Beispiel in der Rolle des Fahrers, wandelt sich sukzessive hin zu einer passiveren Rolle, die durch kontinuierliches Überwachen geprägt ist. Generell kann der Mensch durch Automation entlastet und sein Komfort gesteigert werden. Die Anforderung an den Menschen, seine Aufmerksamkeit konsequent aufrecht zu erhalten, auch wenn er nicht handeln muss, um in unsicheren oder kritischen Situationen kurzfristig in der Lage zu sein, die Steuerung zu übernehmen, stellt allerdings eine Schattenseite des Automationskomforts dar. Unter der Berücksichtigung der zunehmend passiven Rolle des Menschen in hochautomatisierten Verkehrssystemen, gewinnt das Thema der Unterbeanspruchung mit wachsender Automatisierung an Bedeutung. Erhebungsinstrumente zur subjektiven Einschätzung der eigenen Beanspruch differenzieren bislang jedoch nicht klar zwischen einem Unterforderungs- und einem Überforderungsbereich. Vor diesem Hintergrund wurde der {DLR}-{WAT} entwickelt. Der {DLR}–{WAT} umfasst insgesamt acht Subskalen. Auf sechs der acht Subskalen (Beanspruchung durch Informationsaufnahme, Beanspruchung durch Wissensabruf, Beanspruchung durch Entscheidungsfindung, motorische und körperliche Beanspruchung, zeitliche Beanspruchung und Anstrengung) kann der Befragte seinen Beanspruchungszustand angeben, ausgehend von seinem persönlichen Optimum, das in der Mitte jeder Subskala verortet ist. Die zwei weiteren Subskalen des {DLR}-{WAT} (Frustration, Aufgabenbewältigung) sind eindimensional gestaltet, da ein optimales Frustrationsniveau durch Abwesenheit der Frustration gekennzeichnet ist und es nicht möglich ist, eine Aufgabe weniger als gar nicht zu bewältigen. Die Berücksichtigung des persönlichen Optimums der Beanspruchung im {DLR}–{WAT} in den ersten sechs Subskalen ermöglicht im Zuge der Entwicklung hochautomatisierter Verkehrssysteme eine detailliertere Beanspruchungsanalyse als bestehende Fragebögen. Dies eröffnet in der Gestaltung zukünftiger interaktiver Verkehrssysteme die Chance, den schmalen Grat zwischen Überforderung und Unterforderung zielgerichtet zu identifizieren und Aufgaben zwischen Mensch und Automation entsprechend zu verteilen.},
	author = {Grippenkoven, Jan and Rodd, Justin and Brandenburger, Niels},
	date = {2018-03-15},
}

@book{schrills_subjective_2021,
	title = {Subjective Information Processing Awareness Scale ({SIPAS})},
	abstract = {{SIPA} can be defined as the experience of being enabled by a system to perceive, understand, and predict its information processing. The {SIPA} scale is a highly economical unidimensional scale focused on an application in Explainable Artificial Intelligence, as was shown in first empirical studies (Schrills et al., 2021).},
	author = {Schrills, Tim and Franke, Thomas},
	date = {2021-07-16},
}

@inproceedings{madsen_measuring_2000,
	title = {Measuring Human-Computer Trust},
	url = {https://www.semanticscholar.org/paper/Measuring-Human-Computer-Trust-Madsen-Gregor/b8eda9593fbcb63b7ced1866853d9622737533a2},
	abstract = {In this study a psychometric instrument specifically designed to measure human-computer trust ({HCT}) was developed and tested. A rigorous method similar to that described by Moore and Benbasat (1991) was adopted. It was found that both cognitive and affective components of trust could be measured and that, in this study, the affective components were the strongest indicators of trust. The reliability of the instrument, measured as Cronbach's alpha, was 0.94. This instrument is the first of its kind to be specifically designed to measure {HCT} and shown empirically to be valid and reliable.},
	author = {Madsen, M. and Gregor, S.},
	urldate = {2025-06-02},
	date = {2000},
}

@book{laugwitz_construction_2008,
	title = {Construction and Evaluation of a User Experience Questionnaire},
	volume = {5298},
	isbn = {978-3-540-89349-3},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practical relevance of items. Usability experts collected terms and statements on user experience and usability, including ‘hard’ as well as ‘soft’ aspects. These statements were consolidated and transformed into a first questionnaire version containing 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six factors Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and Novelty. Studies conducted for the original German questionnaire and an English version indicate a satisfactory level of reliability and construct validity.},
	pagetotal = {63},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	date = {2008-11-20},
	doi = {10.1007/978-3-540-89350-9_6},
	note = {Journal Abbreviation: {USAB} 2008
Pages: 76
Publication Title: {USAB} 2008},
}

@article{gao_multi-language_2020,
	title = {Multi-Language Toolkit for the System Usability Scale},
	volume = {36},
	doi = {10.1080/10447318.2020.1801173},
	abstract = {The System Usability Scale ({SUS}) is a widely used instrument that measures the subjective usability of products and systems. Although past research has demonstrated the psychometric reliability and criterion-related validity of the {SUS} in specific languages, the approach and methodology of validating the translations has been somewhat inconsistent. This paper addresses this issue by systematically translating and validating the {SUS} across multiple languages. Native speakers of Arabic, Chinese, French, German, Hindi, and Spanish evaluated five common everyday products using the translated {SUS}. Evidence of consistent scale reliability and validity was found in the Chinese, French, German and Spanish {SUS}, with Cronbach’s alpha often greater than .80, as well as large statistically significant correlations between the {SUS} and a one-item adjective rating self-report of overall usability (r =.54-.74). Validity of the {SUS} across languages was also demonstrated by finding reliable differences in mean {SUS} scores between products. Overall, these translated {SUS} measures can be used with confidence in practice to measure the usability of everyday products and systems.},
	pages = {1--19},
	journaltitle = {International Journal of Human-Computer Interaction},
	shortjournal = {International Journal of Human-Computer Interaction},
	author = {Gao, Meiyuzi and Kortum, Phil and Oswald, Frederick},
	date = {2020-08-19},
}
