
@article{saeidnia_artificial_2025,
	title = {Artificial {Intelligence} in the {Battle} against {Disinformation} and {Misinformation}: {A} {Systematic} {Review} of {Challenges} and {Approaches}},
	volume = {67},
	issn = {0219-3116},
	shorttitle = {Artificial {Intelligence} in the {Battle} {Against} {Disinformation} and {Misinformation}},
	url = {https://doi.org/10.1007/s10115-024-02337-7},
	doi = {10.1007/s10115-024-02337-7},
	abstract = {In the rapidly evolving digital age, the proliferation of disinformation and misinformation poses significant challenges to societal trust and information integrity. Recognizing the urgency of addressing this issue, this systematic review endeavors to explore the role of artificial intelligence (AI) in combating the spread of false information. This study aims to provide a comprehensive analysis of how AI technologies have been utilized from 2014 to 2024 to detect, analyze, and mitigate the impact of misinformation across various platforms. This research utilized an exhaustive search across prominent databases such as ProQuest, IEEE Explore, Web of Science, and Scopus. Articles published within the specified timeframe were meticulously screened, resulting in the identification of 8103 studies. Through elimination of duplicates and screening based on title, abstract, and full-text review, we meticulously distilled this vast pool to 76 studies that met the study’s eligibility criteria. Key findings from the review emphasize the advancements and challenges in AI applications for combating misinformation. These findings highlight AI’s capacity to enhance information verification through sophisticated algorithms and natural language processing. They further emphasize the integration of human oversight and continual algorithm refinement emerges as pivotal in augmenting AI’s effectiveness in discerning and countering misinformation. By fostering collaboration across sectors and leveraging the insights gleaned from this study, researchers can propel the development of ethical and effective AI solutions.},
	language = {en},
	number = {4},
	urldate = {2025-05-05},
	journal = {Knowledge and Information Systems},
	author = {Saeidnia, Hamid Reza and Hosseini, Elaheh and Lund, Brady and Tehrani, Maral Alipour and Zaker, Sanaz and Molaei, Saba},
	month = apr,
	year = {2025},
	keywords = {Misinformation, Artificial intelligence, Artificial Intelligence, Disinformation, Review},
	pages = {3139--3158},
	file = {Full Text PDF:C\:\\Users\\linni\\Zotero\\storage\\LTHIDCRN\\Saeidnia et al. - 2025 - Artificial intelligence in the battle against disinformation and misinformation a systematic review.pdf:application/pdf},
}

@article{kumar_feature_2024,
	title = {Feature {Importance} in the {Age} of {Explainable} {AI}: {Case} {Study} of {Detecting} {Fake} {News} \& {Misinformation} via a {Multi}-{Modal} {Framework}},
	volume = {317},
	issn = {0377-2217},
	shorttitle = {Feature {Importance} in the {Age} of {Explainable} {Ai}},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221723007609},
	doi = {10.1016/j.ejor.2023.10.003},
	abstract = {In recent years, fake news has become a global phenomenon due to its explosive growth and ability to leverage multimedia content to manipulate user opinions. Fake news is created by manipulating images, text, audio, and videos, particularly on social media, and the proliferation of such disinformation can trigger detrimental societal effects. False forwarded messages can have a devastating impact on society, spreading propaganda, inciting violence, manipulating public opinion, and even influencing elections. A major shortcoming of existing fake news detection methods is their inability to simultaneously learn and extract features from two modalities and train models with shared representations of multimodal (textual and visual) information. Feature engineering is a critical task in the fake news detection model's machine learning (ML) development process. For ML models to be explainable and trusted, feature engineering should describe how many features used in the ML models contribute to making more accurate predictions. Feature engineering, which plays an important role in the development of an explainable AI system by shaping the features used in the ML models, is an interconnected concept with explainable AI as it affects the model's interpretability. In the research, we develop a fake news detector model in which we (1) identify several textual and visual features that are associated with fake or credible news; specifically, we extract features from article titles, contents, and, top images; (2) investigate the role of all multimodal features (content, emotions and manipulation-based) and combine the cumulative effects using the feature engineering that represent the behavior of fake news propagators; and (3) develop a model to detect disinformation on benchmark multimodal datasets consisting of text and images. We conduct experiments on several real-world multimodal fake news datasets, and our results show that on average, our model outperforms existing single-modality methods by large margins that do not use any feature optimization techniques.},
	number = {2},
	urldate = {2025-05-05},
	journal = {European Journal of Operational Research},
	author = {Kumar, Ajay and Taylor, James W.},
	month = sep,
	year = {2024},
	keywords = {Analytics, Explainable data analytics, Feature selection, Machine learning, Optimization algorithm},
	pages = {401--413},
	file = {PDF:C\:\\Users\\linni\\Zotero\\storage\\X3WZCCCT\\Kumar und Taylor - 2024 - Feature importance in the age of explainable AI Case study of detecting fake news & misinformation.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\linni\\Zotero\\storage\\3R3SWGNB\\S0377221723007609.html:text/html},
}

@inproceedings{seneviratne_blockchain_2022,
	address = {Barcelona Spain},
	title = {Blockchain for {Social} {Good}: {Combating} {Misinformation} on the {Web} with {AI} and {Blockchain}},
	isbn = {978-1-4503-9191-7},
	shorttitle = {Blockchain for {Social} {Good}},
	url = {https://dl.acm.org/doi/10.1145/3501247.3539016},
	doi = {10.1145/3501247.3539016},
	abstract = {The spread of deceptive or misleading information, commonly referred to as misinformation, poses a social, economic, and political threat. Such deceptive information spreads quickly and inexpensively. For example, with the hype around blockchain technologies, misinformation on “get rich quick” scams on the Web is rampant, as evidenced by sophisticated Twitter hacks of celebrities and many social media posts that bait unsuspecting users to visit phishing websites. Unfortunately, AI technologies have contributed to the growing pains of misinformation on the Web, with the advances in technologies such as generative adversarial deep learning techniques that can generate “deep fakes” for nefarious purposes. At the same time, researchers are working on a different set of AI technologies to combat misinformation, akin to “fighting fire with fire.” As there is no clear way to win the online “cat-and-mouse” game against fake news generators and spreaders of misinformation, we believe social media platforms could be fortified with blockchain and AI technologies to mitigate the extent of misinformation propagation in various communities worldwide. Tamperproof blockchain techniques can provide irrefutable evidence of what content is authentic, guaranteeing how the information has evolved with provenance trails. Various AI models that could be used for detecting fake news can be served on a blockchain for the effective and transparent utility of the model. Such a synergistic combination of AI and blockchain is a burgeoning area of research. This paper outlines a proposal for combining blockchain and AI techniques for handling misinformation on the Web and highlights some of the early ongoing work in this space.},
	language = {en},
	urldate = {2025-05-05},
	booktitle = {14th {ACM} {Web} {Science} {Conference} 2022},
	publisher = {ACM},
	author = {Seneviratne, Oshani},
	month = jun,
	year = {2022},
	pages = {435--442},
	file = {PDF:C\:\\Users\\linni\\Zotero\\storage\\5XA5UMVR\\Seneviratne - 2022 - Blockchain for Social Good Combating Misinformation on the Web with AI and Blockchain.pdf:application/pdf},
}

@article{franke_personal_2019,
	title = {A {Personal} {Resource} for {Technology} {Interaction}: {Development} and {Validation} of the {Affinity} for {Technology} {Interaction} ({ATI}) {Scale}},
	volume = {35},
	issn = {1532-7590},
	shorttitle = {A {Personal} {Resource} for {Technology} {Interaction}},
	doi = {10.1080/10447318.2018.1456150},
	abstract = {Successful coping with technology is relevant for mastering daily life. Based on related conceptions, we propose affinity for technology interaction (ATI), defined as the tendency to actively engage in intensive technology interaction, as a key personal resource for coping with technology. We present the 9-item ATI scale, an economical unidimensional scale that assesses ATI as an interaction style rooted in the construct need for cognition (NFC). Results of multiple studies (n {\textgreater} 1500) showed that the scale achieves good to excellent reliability, exhibits expected moderate to high correlations with geekism, technology enthusiasm, NFC, self-reported success in technical problem-solving and technical system learning success, and also with usage of technical systems. Further, correlations of ATI with the Big Five personality dimensions were weak at most. Based on the results, the ATI scale appears to be a promising tool for research applications such as the characterization of user diversity in system usability tests and the construction of general models of user-technology interaction. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	number = {6},
	journal = {International Journal of Human-Computer Interaction},
	author = {Franke, Thomas and Attig, Christiane and Wessel, Daniel},
	year = {2019},
	note = {Place: United Kingdom
Publisher: Taylor \& Francis},
	keywords = {Adult Attitudes, Attitude Measures, Rating Scales, Technology, Test Construction, Test Validity},
	pages = {456--467},
	file = {Snapshot:C\:\\Users\\linni\\Zotero\\storage\\QDKQTF3V\\2019-10130-002.html:text/html},
}

@book{grippenkoven_dlr-wat_2018,
	title = {{DLR}-{Wat}: {Ein} {Instrument} zur {Untersuchung} des {Optimalen} {Beanspruchungsniveaus} in {Hochautomatisierten} {Mensch}-{Maschine}-{Systemen}},
	shorttitle = {Dlr-{Wat}},
	abstract = {In diesem Artikel wird das „DLR - Workload Assessment Tool“ (DLR–WAT) vorgestellt, ein Fragebogen zur Selbsteinschätzung der Beanspruchung, der gezielter als bestehende Messwerkzeuge wie z.B. der NASA-TLX Abweichungen von einem subjektiven Optimum der Beanspruchung berücksichtigt. Automatisierung und Digitalisierung sind derzeit die bestimmenden Trends im Personen- und Güterverkehr. Ob auf der Straße, der Schiene oder in der Luft, die Rolle des Menschen im Verkehr wandelt sich im Angesicht dieser Entwicklungen rapide. Technische Assistenzen unterstützen den Menschen und hochautomatisierte Systeme übernehmen in einzelnen Bereichen bereits Aufgaben des Menschen wie z.B. die Steuerung und Navigation. Die aktive Rolle des Menschen, zum Beispiel in der Rolle des Fahrers, wandelt sich sukzessive hin zu einer passiveren Rolle, die durch kontinuierliches Überwachen geprägt ist. Generell kann der Mensch durch Automation entlastet und sein Komfort gesteigert werden. Die Anforderung an den Menschen, seine Aufmerksamkeit konsequent aufrecht zu erhalten, auch wenn er nicht handeln muss, um in unsicheren oder kritischen Situationen kurzfristig in der Lage zu sein, die Steuerung zu übernehmen, stellt allerdings eine Schattenseite des Automationskomforts dar. Unter der Berücksichtigung der zunehmend passiven Rolle des Menschen in hochautomatisierten Verkehrssystemen, gewinnt das Thema der Unterbeanspruchung mit wachsender Automatisierung an Bedeutung. Erhebungsinstrumente zur subjektiven Einschätzung der eigenen Beanspruch differenzieren bislang jedoch nicht klar zwischen einem Unterforderungs- und einem Überforderungsbereich. Vor diesem Hintergrund wurde der DLR-WAT entwickelt. Der DLR–WAT umfasst insgesamt acht Subskalen. Auf sechs der acht Subskalen (Beanspruchung durch Informationsaufnahme, Beanspruchung durch Wissensabruf, Beanspruchung durch Entscheidungsfindung, motorische und körperliche Beanspruchung, zeitliche Beanspruchung und Anstrengung) kann der Befragte seinen Beanspruchungszustand angeben, ausgehend von seinem persönlichen Optimum, das in der Mitte jeder Subskala verortet ist. Die zwei weiteren Subskalen des DLR-WAT (Frustration, Aufgabenbewältigung) sind eindimensional gestaltet, da ein optimales Frustrationsniveau durch Abwesenheit der Frustration gekennzeichnet ist und es nicht möglich ist, eine Aufgabe weniger als gar nicht zu bewältigen. Die Berücksichtigung des persönlichen Optimums der Beanspruchung im DLR–WAT in den ersten sechs Subskalen ermöglicht im Zuge der Entwicklung hochautomatisierter Verkehrssysteme eine detailliertere Beanspruchungsanalyse als bestehende Fragebögen. Dies eröffnet in der Gestaltung zukünftiger interaktiver Verkehrssysteme die Chance, den schmalen Grat zwischen Überforderung und Unterforderung zielgerichtet zu identifizieren und Aufgaben zwischen Mensch und Automation entsprechend zu verteilen.},
	author = {Grippenkoven, Jan and Rodd, Justin and Brandenburger, Niels},
	month = mar,
	year = {2018},
}

@book{schrills_subjective_2021,
	title = {Subjective {Information} {Processing} {Awareness} {Scale} ({SIPAS})},
	abstract = {SIPA can be defined as the experience of being enabled by a system to perceive, understand, and predict its information processing. The SIPA scale is a highly economical unidimensional scale focused on an application in Explainable Artificial Intelligence, as was shown in first empirical studies (Schrills et al., 2021).},
	author = {Schrills, Tim and Franke, Thomas},
	month = jul,
	year = {2021},
}

@inproceedings{madsen_measuring_2000,
	title = {Measuring {Human}-{Computer} {Trust}},
	url = {https://www.semanticscholar.org/paper/Measuring-Human-Computer-Trust-Madsen-Gregor/b8eda9593fbcb63b7ced1866853d9622737533a2},
	abstract = {In this study a psychometric instrument specifically designed to measure human-computer trust (HCT) was developed and tested. A rigorous method similar to that described by Moore and Benbasat (1991) was adopted. It was found that both cognitive and affective components of trust could be measured and that, in this study, the affective components were the strongest indicators of trust. The reliability of the instrument, measured as Cronbach's alpha, was 0.94. This instrument is the first of its kind to be specifically designed to measure HCT and shown empirically to be valid and reliable.},
	urldate = {2025-06-02},
	author = {Madsen, M. and Gregor, S.},
	year = {2000},
}

@book{laugwitz_construction_2008,
	title = {Construction and {Evaluation} of a {User} {Experience} {Questionnaire}},
	volume = {5298},
	isbn = {978-3-540-89349-3},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practical relevance of items. Usability experts collected terms and statements on user experience and usability, including ‘hard’ as well as ‘soft’ aspects. These statements were consolidated and transformed into a first questionnaire version containing 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six factors Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and Novelty. Studies conducted for the original German questionnaire and an English version indicate a satisfactory level of reliability and construct validity.},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	month = nov,
	year = {2008},
	doi = {10.1007/978-3-540-89350-9_6},
	note = {Journal Abbreviation: USAB 2008
Pages: 76
Publication Title: USAB 2008},
}

@article{gao_multi-language_2020,
	title = {Multi-{Language} {Toolkit} for the {System} {Usability} {Scale}},
	volume = {36},
	doi = {10.1080/10447318.2020.1801173},
	abstract = {The System Usability Scale (SUS) is a widely used instrument that measures the subjective usability of products and systems. Although past research has demonstrated the psychometric reliability and criterion-related validity of the SUS in specific languages, the approach and methodology of validating the translations has been somewhat inconsistent. This paper addresses this issue by systematically translating and validating the SUS across multiple languages. Native speakers of Arabic, Chinese, French, German, Hindi, and Spanish evaluated five common everyday products using the translated SUS. Evidence of consistent scale reliability and validity was found in the Chinese, French, German and Spanish SUS, with Cronbach’s alpha often greater than .80, as well as large statistically significant correlations between the SUS and a one-item adjective rating self-report of overall usability (r =.54-.74). Validity of the SUS across languages was also demonstrated by finding reliable differences in mean SUS scores between products. Overall, these translated SUS measures can be used with confidence in practice to measure the usability of everyday products and systems.},
	journal = {International Journal of Human-Computer Interaction},
	author = {Gao, Meiyuzi and Kortum, Phil and Oswald, Frederick},
	month = aug,
	year = {2020},
	pages = {1--19},
}

@article{braun_using_2006,
	title = {Using {Thematic} {Analysis} in {Psychology}},
	volume = {3},
	issn = {1478-0887},
	url = {https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa},
	doi = {10.1191/1478088706qp063oa},
	abstract = {Thematic analysis is a poorly demarcated, rarely acknowledged, yet widely used qualitative analytic method within psychology. In this paper, we argue that it offers an accessible and theoretically flexible approach to analysing qualitative data. We outline what thematic analysis is, locating it in relation to other qualitative analytic methods that search for themes or patterns, and in relation to different epistemological and ontological positions. We then provide clear guidelines to those wanting to start thematic analysis, or conduct it in a more deliberate and rigorous way, and consider potential pitfalls in conducting thematic analysis. Finally, we outline the disadvantages and advantages of thematic analysis. We conclude by advocating thematic analysis as a useful and flexible method for qualitative research in and beyond psychology.},
	number = {2},
	urldate = {2025-07-11},
	journal = {Qualitative Research in Psychology},
	author = {Braun, Virginia and Clarke, Victoria},
	month = jan,
	year = {2006},
	note = {Publisher: Routledge
\_eprint: https://www.tandfonline.com/doi/pdf/10.1191/1478088706qp063oa},
	keywords = {epistemology, flexibility, patterns, qualitative psychology, thematic analysis},
	pages = {77--101},
}

@article{yeomans_making_2019,
	title = {Making {Sense} of {Recommendations}},
	volume = {32},
	issn = {1099-0771},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bdm.2118},
	abstract = {{\textless}em{\textgreater}Journal of Behavioral Decision Making{\textless}/em{\textgreater} is a behavioural psychology journal for developments in the psychological theory of decision processes \& decision neuroscience.},
	language = {en},
	number = {4},
	urldate = {2025-07-11},
	journal = {Journal of Behavioral Decision Making},
	author = {Yeomans, Michael and Shah, Anuj and Mullainathan, Sendhil and Kleinberg, Jon},
	month = oct,
	year = {2019},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {403--414},
}

@article{logg_algorithm_2019,
	title = {Algorithm {Appreciation}: {People} {Prefer} {Algorithmic} to {Human} {Judgment}},
	volume = {151},
	issn = {0749-5978},
	shorttitle = {Algorithm {Appreciation}},
	url = {https://www.sciencedirect.com/science/article/pii/S0749597818303388},
	doi = {10.1016/j.obhdp.2018.12.005},
	abstract = {Even though computational algorithms often outperform human judgment, received wisdom suggests that people may be skeptical of relying on them (Dawes, 1979). Counter to this notion, results from six experiments show that lay people adhere more to advice when they think it comes from an algorithm than from a person. People showed this effect, what we call algorithm appreciation, when making numeric estimates about a visual stimulus (Experiment 1A) and forecasts about the popularity of songs and romantic attraction (Experiments 1B and 1C). Yet, researchers predicted the opposite result (Experiment 1D). Algorithm appreciation persisted when advice appeared jointly or separately (Experiment 2). However, algorithm appreciation waned when: people chose between an algorithm’s estimate and their own (versus an external advisor’s; Experiment 3) and they had expertise in forecasting (Experiment 4). Paradoxically, experienced professionals, who make forecasts on a regular basis, relied less on algorithmic advice than lay people did, which hurt their accuracy. These results shed light on the important question of when people rely on algorithmic advice over advice from people and have implications for the use of “big data” and algorithmic advice it generates.},
	urldate = {2025-07-11},
	journal = {Organizational Behavior and Human Decision Processes},
	author = {Logg, Jennifer M. and Minson, Julia A. and Moore, Don A.},
	month = mar,
	year = {2019},
	keywords = {Accuracy, Advice-taking, Algorithms, Decision-making, Forecasting, Theory of machine},
	pages = {90--103},
	file = {ScienceDirect Snapshot:C\:\\Users\\linni\\Zotero\\storage\\3RKSVMNB\\S0749597818303388.html:text/html},
}

@article{lewandowsky_beyond_2017,
	title = {Beyond {Misinformation}: {Understanding} and {Coping} with the “{Post}-{Truth}” {Era}},
	volume = {6},
	issn = {2211-369X},
	shorttitle = {Beyond {Misinformation}},
	doi = {10.1016/j.jarmac.2017.07.008},
	abstract = {The terms “post-truth” and “fake news” have become increasingly prevalent in public discourse over the last year. This article explores the growing abundance of misinformation, how it influences people, and how to counter it. We examine the ways in which misinformation can have an adverse impact on society. We summarize how people respond to corrections of misinformation, and what kinds of corrections are most effective. We argue that to be effective, scientific research into misinformation must be considered within a larger political, technological, and societal context. The post-truth world emerged as a result of societal mega-trends such as a decline in social capital, growing economic inequality, increased polarization, declining trust in science, and an increasingly fractionated media landscape. We suggest that responses to this malaise must involve technological solutions incorporating psychological principles, an interdisciplinary approach that we describe as “technocognition.” We outline a number of recommendations to counter misinformation in a post-truth world. (PsycInfo Database Record (c) 2025 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Applied Research in Memory and Cognition},
	author = {Lewandowsky, Stephan and Ecker, Ullrich K. H. and Cook, John},
	year = {2017},
	note = {Place: Netherlands
Publisher: Elsevier Science},
	keywords = {Coping Behavior, Information, Politics, Public Opinion, Social Capital, Society, Truth},
	pages = {353--369},
	file = {Eingereichte Version:C\:\\Users\\linni\\Zotero\\storage\\RAXCVM9F\\Lewandowsky et al. - 2017 - Beyond misinformation Understanding and coping with the “post-truth” era.pdf:application/pdf;Snapshot:C\:\\Users\\linni\\Zotero\\storage\\DDHYGWWQ\\doiLanding.html:text/html},
}
