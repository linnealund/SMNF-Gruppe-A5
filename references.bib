
@inproceedings{seneviratne_blockchain_2022,
	location = {New York, {NY}, {USA}},
	title = {Blockchain for Social Good: Combating Misinformation on the Web with {AI} and Blockchain},
	isbn = {978-1-4503-9191-7},
	url = {https://doi.org/10.1145/3501247.3539016},
	doi = {10.1145/3501247.3539016},
	series = {{WebSci} '22},
	shorttitle = {Blockchain for Social Good},
	abstract = {The spread of deceptive or misleading information, commonly referred to as misinformation, poses a social, economic, and political threat. Such deceptive information spreads quickly and inexpensively. For example, with the hype around blockchain technologies, misinformation on “get rich quick” scams on the Web is rampant, as evidenced by sophisticated Twitter hacks of celebrities and many social media posts that bait unsuspecting users to visit phishing websites. Unfortunately, {AI} technologies have contributed to the growing pains of misinformation on the Web, with the advances in technologies such as generative adversarial deep learning techniques that can generate “deep fakes” for nefarious purposes. At the same time, researchers are working on a different set of {AI} technologies to combat misinformation, akin to “fighting fire with fire.” As there is no clear way to win the online “cat-and-mouse” game against fake news generators and spreaders of misinformation, we believe social media platforms could be fortified with blockchain and {AI} technologies to mitigate the extent of misinformation propagation in various communities worldwide. Tamper-proof blockchain techniques can provide irrefutable evidence of what content is authentic, guaranteeing how the information has evolved with provenance trails. Various {AI} models that could be used for detecting fake news can be served on a blockchain for the effective and transparent utility of the model. Such a synergistic combination of {AI} and blockchain is a burgeoning area of research. This paper outlines a proposal for combining blockchain and {AI} techniques for handling misinformation on the Web and highlights some of the early ongoing work in this space.},
	pages = {435--442},
	booktitle = {Proceedings of the 14th {ACM} Web Science Conference 2022},
	publisher = {Association for Computing Machinery},
	author = {Seneviratne, Oshani},
	urldate = {2025-05-04},
	date = {2022-06-26},
}

@article{v_cognitive_2022,
	title = {Cognitive {AI} for Mitigation of Misinformation in Online Social Networks},
	volume = {24},
	issn = {1941-045X},
	url = {https://ieeexplore.ieee.org/document/9967399},
	doi = {10.1109/MITP.2022.3168790},
	abstract = {Misinformation propagation in social networks has emerged as a crucial problem that needs to be attended with prime importance. Despite the existence of several fact-checking mechanisms and misinformation detection tools, users of social media platforms continue to be the victims of misinformation propagation. This is because human cognition is a strong factor that drives users in consuming and spreading misinformation. This article highlights the significance of cognitive psychology in misinformation propagation analysis and summarizes the challenges faced by current misinformation detection mechanisms. The study shows that there is an immediate requirement for efficient mechanisms combining {AI} and cognitive psychology that can support humans in making judgements regarding the information appearing on social networks. A cognitive {AI} framework is proposed that can augment humans’ capability in assessing the veracity of the information online and reinforce positive information sharing behavior in individuals thereby reducing the spread of misinformation.},
	pages = {37--45},
	number = {5},
	journaltitle = {{IT} Professional},
	author = {V, Indu and Thampi, Sabu M.},
	urldate = {2025-05-05},
	date = {2022-09},
	keywords = {Artificial intelligence, Cognition, Fake news, Feature extraction, Information sharing, Psychology, Social networking (online)},
	file = {Snapshot:C\:\\Users\\linni\\Zotero\\storage\\SSHHMLTU\\9967399.html:text/html},
}

@article{saeidnia_artificial_2025,
	title = {Artificial intelligence in the battle against disinformation and misinformation: a systematic review of challenges and approaches},
	volume = {67},
	issn = {0219-3116},
	url = {https://doi.org/10.1007/s10115-024-02337-7},
	doi = {10.1007/s10115-024-02337-7},
	shorttitle = {Artificial intelligence in the battle against disinformation and misinformation},
	abstract = {In the rapidly evolving digital age, the proliferation of disinformation and misinformation poses significant challenges to societal trust and information integrity. Recognizing the urgency of addressing this issue, this systematic review endeavors to explore the role of artificial intelligence ({AI}) in combating the spread of false information. This study aims to provide a comprehensive analysis of how {AI} technologies have been utilized from 2014 to 2024 to detect, analyze, and mitigate the impact of misinformation across various platforms. This research utilized an exhaustive search across prominent databases such as {ProQuest}, {IEEE} Explore, Web of Science, and Scopus. Articles published within the specified timeframe were meticulously screened, resulting in the identification of 8103 studies. Through elimination of duplicates and screening based on title, abstract, and full-text review, we meticulously distilled this vast pool to 76 studies that met the study’s eligibility criteria. Key findings from the review emphasize the advancements and challenges in {AI} applications for combating misinformation. These findings highlight {AI}’s capacity to enhance information verification through sophisticated algorithms and natural language processing. They further emphasize the integration of human oversight and continual algorithm refinement emerges as pivotal in augmenting {AI}’s effectiveness in discerning and countering misinformation. By fostering collaboration across sectors and leveraging the insights gleaned from this study, researchers can propel the development of ethical and effective {AI} solutions.},
	pages = {3139--3158},
	number = {4},
	journaltitle = {Knowledge and Information Systems},
	shortjournal = {Knowl Inf Syst},
	author = {Saeidnia, Hamid Reza and Hosseini, Elaheh and Lund, Brady and Tehrani, Maral Alipour and Zaker, Sanaz and Molaei, Saba},
	urldate = {2025-05-05},
	date = {2025-04-01},
	langid = {english},
	keywords = {Artificial intelligence, Artificial Intelligence, Disinformation, Misinformation, Review},
	file = {Full Text PDF:C\:\\Users\\linni\\Zotero\\storage\\LTHIDCRN\\Saeidnia et al. - 2025 - Artificial intelligence in the battle against disinformation and misinformation a systematic review.pdf:application/pdf},
}

@article{kumar_feature_2024,
	title = {Feature importance in the age of explainable {AI}: Case study of detecting fake news \& misinformation via a multi-modal framework},
	volume = {317},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221723007609},
	doi = {10.1016/j.ejor.2023.10.003},
	shorttitle = {Feature importance in the age of explainable {AI}},
	abstract = {In recent years, fake news has become a global phenomenon due to its explosive growth and ability to leverage multimedia content to manipulate user opinions. Fake news is created by manipulating images, text, audio, and videos, particularly on social media, and the proliferation of such disinformation can trigger detrimental societal effects. False forwarded messages can have a devastating impact on society, spreading propaganda, inciting violence, manipulating public opinion, and even influencing elections. A major shortcoming of existing fake news detection methods is their inability to simultaneously learn and extract features from two modalities and train models with shared representations of multimodal (textual and visual) information. Feature engineering is a critical task in the fake news detection model's machine learning ({ML}) development process. For {ML} models to be explainable and trusted, feature engineering should describe how many features used in the {ML} models contribute to making more accurate predictions. Feature engineering, which plays an important role in the development of an explainable {AI} system by shaping the features used in the {ML} models, is an interconnected concept with explainable {AI} as it affects the model's interpretability. In the research, we develop a fake news detector model in which we (1) identify several textual and visual features that are associated with fake or credible news; specifically, we extract features from article titles, contents, and, top images; (2) investigate the role of all multimodal features (content, emotions and manipulation-based) and combine the cumulative effects using the feature engineering that represent the behavior of fake news propagators; and (3) develop a model to detect disinformation on benchmark multimodal datasets consisting of text and images. We conduct experiments on several real-world multimodal fake news datasets, and our results show that on average, our model outperforms existing single-modality methods by large margins that do not use any feature optimization techniques.},
	pages = {401--413},
	number = {2},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Kumar, Ajay and Taylor, James W.},
	urldate = {2025-05-05},
	date = {2024-09-01},
	keywords = {Analytics, Explainable data analytics, Feature selection, Machine learning, Optimization algorithm},
	file = {PDF:C\:\\Users\\linni\\Zotero\\storage\\X3WZCCCT\\Kumar und Taylor - 2024 - Feature importance in the age of explainable AI Case study of detecting fake news & misinformation.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\linni\\Zotero\\storage\\3R3SWGNB\\S0377221723007609.html:text/html},
}
